{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_param=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_param, 1, bias=False)\n",
    "#         self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "#         x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 2, 3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_module(module, memo=None):\n",
    "\n",
    "    if memo is None:\n",
    "        memo = {}\n",
    "\n",
    "    # Create a copy of the module.\n",
    "    # https://github.com/pytorch/pytorch/blob/65bad41cbec096aa767b3752843eddebf845726f/torch/nn/modules/module.py#L1171\n",
    "    if not isinstance(module, torch.nn.Module):\n",
    "        return module\n",
    "    clone = module.__new__(type(module))\n",
    "    clone.__dict__ = module.__dict__.copy()\n",
    "    clone._parameters = clone._parameters.copy()\n",
    "    clone._buffers = clone._buffers.copy()\n",
    "    clone._modules = clone._modules.copy()\n",
    "\n",
    "    # Re-write all parameters\n",
    "    if hasattr(clone, '_parameters'):\n",
    "        for param_key in clone._parameters:\n",
    "            if module._parameters[param_key] is not None:\n",
    "                param = module._parameters[param_key]\n",
    "                param_ptr = param.data_ptr\n",
    "                if param_ptr in memo:\n",
    "                    clone._parameters[param_key] = memo[param_ptr]\n",
    "                else:\n",
    "                    cloned = param.clone()\n",
    "                    clone._parameters[param_key] = cloned\n",
    "                    memo[param_ptr] = cloned\n",
    "\n",
    "    # Then, recurse for each submodule\n",
    "    if hasattr(clone, '_modules'):\n",
    "        for module_key in clone._modules:\n",
    "            clone._modules[module_key] = clone_module(\n",
    "                module._modules[module_key],\n",
    "                memo=memo,\n",
    "            )\n",
    "\n",
    "    # Finally, rebuild the flattened parameters for RNNs\n",
    "    if hasattr(clone, 'flatten_parameters'):\n",
    "        clone = clone._apply(lambda x: x)\n",
    "    return clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(module, memo=None):\n",
    "    if memo is None:\n",
    "        memo = {}\n",
    "\n",
    "    # Update the params\n",
    "    for param_key in module._parameters:\n",
    "        p = module._parameters[param_key]\n",
    "        if p is not None and hasattr(p, 'update') and p.update is not None:\n",
    "            if p in memo:\n",
    "                module._parameters[param_key] = memo[p]\n",
    "            else:\n",
    "                updated = p + p.update\n",
    "                memo[p] = updated\n",
    "                module._parameters[param_key] = updated\n",
    "\n",
    "    # Then, recurse for each submodule\n",
    "    for module_key in module._modules:\n",
    "        module._modules[module_key] = update(\n",
    "            module._modules[module_key],\n",
    "            memo=memo,\n",
    "        )\n",
    "\n",
    "    # Rebuild the flattened parameters for RNNs\n",
    "    if hasattr(module, 'flatten_parameters'):\n",
    "        module._apply(lambda x: x)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(model, out, lr=0.1, debug=False):\n",
    "    ok_params = (p for p in model.parameters() if p.requires_grad)\n",
    "    grad = torch.autograd.grad(out, ok_params, create_graph=True)\n",
    "    \n",
    "    ok_params = (p for p in model.parameters() if p.requires_grad)\n",
    "    for p, g in zip(ok_params, grad):\n",
    "        if g is not None:\n",
    "            if debug:\n",
    "                print(f\"Gradient : {g}\")\n",
    "            p.update = -lr * g\n",
    "    return update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_state_dict = {}\n",
    "# for p1, p2 in zip(m1.parameters(), m2.parameters()):\n",
    "#     p2[:] = p1.clone()\n",
    "#     p2._copy(p1.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1: Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1400, 0.6083]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(m1.linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_optim = optim.SGD(m1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model orig: Parameter containing:\n",
      "tensor([[0.1400, 0.6083]], requires_grad=True)\n",
      "Model clone: tensor([[0.0400, 0.5083]], grad_fn=<AddBackward0>)\n",
      "tensor([[0., 1.]])\n",
      "\n",
      "Model orig: Parameter containing:\n",
      "tensor([[0.1400, 0.6083]], requires_grad=True)\n",
      "Model clone: tensor([[-0.0600,  0.4083]], grad_fn=<AddBackward0>)\n",
      "tensor([[0., 5.]])\n",
      "\n",
      "Model orig: Parameter containing:\n",
      "tensor([[0.1400, 0.6083]], requires_grad=True)\n",
      "Model clone: tensor([[-0.1600,  0.3083]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0., 14.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outer_optim.zero_grad()\n",
    "for t in range(3):\n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    m2 = clone_module(m1)\n",
    "    \n",
    "    x = torch.ones(2) * (t+1)\n",
    "    out = m2(x)\n",
    "    \n",
    "    backprop(m2, out)\n",
    "    \n",
    "    print(f\"Model orig: {m1.linear.weight}\")\n",
    "    print(f\"Model clone: {m2.linear.weight}\")\n",
    "    \n",
    "    x2 = torch.tensor([0.0, (t+1)**2])\n",
    "    out2 = m2(x2)\n",
    "    out2.backward()\n",
    "    print(m1.linear.weight.grad)\n",
    "#     print(torch.autograd.grad(out2, m1.parameters()))\n",
    "    \n",
    "    total += out2\n",
    "    count += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0., 14.]])\n"
     ]
    }
   ],
   "source": [
    "total /= count\n",
    "# outer_optim.zero_grad()\n",
    "# total.backward()\n",
    "print(m1.linear.weight.grad)\n",
    "outer_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1400, -0.7917]], requires_grad=True)\n",
      "tensor([[-0.1600,  0.3083]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(m1.linear.weight)\n",
    "print(m2.linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ComplexModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2575, -0.1216, -0.2419],\n",
      "          [ 0.3088, -0.2674,  0.1279],\n",
      "          [ 0.0775, -0.1218,  0.0791]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2890, -0.0700,  0.1894],\n",
      "          [-0.1374,  0.2413, -0.1832],\n",
      "          [ 0.3039,  0.2421, -0.1715]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(m1.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_optim = optim.SGD(m1.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No change: True\n",
      "Support loss 0.01822948455810547\n",
      "Query loss 0.23389102518558502\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "\n",
      "No change: True\n",
      "Support loss 0.9629865288734436\n",
      "Query loss 0.3391243815422058\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "\n",
      "No change: True\n",
      "Support loss 0.1363360732793808\n",
      "Query loss 0.6685811877250671\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outer_optim.zero_grad()\n",
    "for t in range(3):\n",
    "    total = 0.0\n",
    "    count = 0\n",
    "    m2 = clone_module(m1)\n",
    "    \n",
    "    x = torch.randn(1, 1, 5, 5)\n",
    "    out = m2(x).sum()\n",
    "    gt = torch.sin(x.sum())\n",
    "    loss = (gt - out) ** 2\n",
    "    \n",
    "#     grads = torch.autograd.grad(loss, (p for p in m2.parameters() if p.requires_grad), create_graph=True)\n",
    "    backprop(m2, loss, lr=0.001)\n",
    "    \n",
    "    print(f\"No change: {torch.allclose(m1.conv.weight, m2.conv.weight)}\")\n",
    "    print(f\"Support loss {loss.item()}\")\n",
    "#     print(f\"Model orig: {m1.conv.weight}\")\n",
    "#     print(f\"Model clone: {m2.conv.weight}\")\n",
    "    \n",
    "    x2 = torch.randn(1, 1, 5, 5)\n",
    "    out2 = m2(x2).sum()\n",
    "    gt2 = torch.sin(x2.sum())\n",
    "    loss2 = (gt2 - out2) ** 2\n",
    "    loss2.backward()\n",
    "    print(f\"Query loss {loss2.item()}\")\n",
    "    print(m1.conv.weight.grad)\n",
    "#     print(torch.autograd.grad(out2, m1.parameters()))\n",
    "    \n",
    "    total += loss2\n",
    "    count += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6686, grad_fn=<AddBackward0>)\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(total)\n",
    "total /= count\n",
    "# outer_optim.zero_grad()\n",
    "# total.backward()\n",
    "print(m1.conv.weight.grad)\n",
    "outer_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1967, -0.3055,  0.0550],\n",
      "          [ 0.1962,  0.1963,  0.1426],\n",
      "          [ 0.1129,  0.2057,  0.2414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2165,  0.1041, -0.0909],\n",
      "          [ 0.1635, -0.0960, -0.2761],\n",
      "          [ 0.3091, -0.0802,  0.0284]]]], requires_grad=True)\n",
      "tensor([[[[ 0.2164, -0.2719,  0.0461],\n",
      "          [ 0.1779,  0.2398,  0.1853],\n",
      "          [ 0.1554,  0.1954,  0.1766]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1904,  0.3132, -0.1621],\n",
      "          [ 0.2632, -0.1344, -0.1651],\n",
      "          [ 0.2386, -0.0665,  0.1100]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(m1.conv.weight)\n",
    "print(m2.conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3: SimpleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: This requires specific models from the repo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
